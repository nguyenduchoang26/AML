{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "321a7bef",
   "metadata": {},
   "source": [
    "# Applied Machine Learning (2021), exercises\n",
    "\n",
    "\n",
    "## General instructions for all exercises\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Follow the instructions and fill in your solution under the line marked by tag\n",
    "\n",
    "> YOUR CODE HERE\n",
    "\n",
    "Do not change other areas of the document, since it may disturb the autograding of your results!\n",
    "  \n",
    "Having written the answer, execute the code cell by and pressing `Shift-Enter` key combination. The code is run, and it may print some information under the code cell. The focus automatically moves to the next cell and you may \"execute\" that cell by pressing `Shift-Enter` again, until you have reached the code cell which tests your solution. Execute that and follow the feedback. Usually it either says that the solution seems acceptable, or reports some errors. You can go back to your solution, modify it and repeat everything until you are satisfied. Then proceed to the next task.\n",
    "   \n",
    "Repeat the process for all tasks.\n",
    "\n",
    "The notebook may also contain manually graded answers. Write your manualle graded answer under the line marked by tag:\n",
    "\n",
    "> YOUR ANSWER HERE\n",
    "\n",
    "Manually graded tasks may be text, pseudocode, or mathematical formulas. You can write formulas with $\\LaTeX$-syntax by enclosing the formula with dollar signs (`$`), for example `$f(x)=2 \\pi / \\alpha$`, will produce $f(x)=2 \\pi / \\alpha$\n",
    "\n",
    "When you have passed the tests in the notebook, and you are ready to submit your solutions, download the whole notebook, using menu `File -> Download as -> Notebook (.ipynb)`. Save the file in your hard disk, and submit it in [Moodle](https://moodle.uwasa.fi) under the corresponding excercise.\n",
    "\n",
    "Your solution should be an executable Python code. Use the code already existing as an example of Python programing and read more from the numerous Python programming material from the Internet if necessary. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f57153",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "Student_number = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c486325",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c06ee9f",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b11e9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T18:25:43.126454Z",
     "start_time": "2021-11-26T18:25:42.079134Z"
    }
   },
   "outputs": [],
   "source": [
    "# Standard libraries to be used\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "\n",
    "# Import the NLTK library\n",
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk.stem import  WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import pyLDAvis\n",
    "from pyLDAvis import gensim_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5fe049",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T18:25:43.285977Z",
     "start_time": "2021-11-26T18:25:43.128166Z"
    }
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3660519d",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Read the sample dataset containing 2491 short sentences each in separate lines. The first five lines of the dataset are shown below:\n",
    "\n",
    "`\n",
    "Innovation in Database Management: Computer Science vs. Engineering.\n",
    "High performance prime field multiplication for GPU.\n",
    "enchanted scissors: a scissor interface for support in cutting and interactive fabrication.\n",
    "Detection of channel degradation attack by Intermediary Node in Linear Networks.\n",
    "Pinning a Complex Network through the Betweenness Centrality Strategy.\n",
    "`\n",
    "\n",
    "Read the data and prepare that for ML using the following phases:\n",
    "\n",
    " - Read the dataset `dataset.txt` using for example PlaintextCorpusReader\n",
    " - Tokenize the dataset to words\n",
    "     - if data is the text data returned by PlaintextCorpusReader, you may find data.sents() as a convenient function to tokenize every line \n",
    " - Remove all words which are shorter than 5 characters\n",
    " - Remove all english stop words\n",
    " - Lemmatize words\n",
    " \n",
    "Store the result in list called as `words`. Make sure that the list contains 2491 sublists, which contain a few words each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91863129",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T18:25:44.623751Z",
     "start_time": "2021-11-26T18:25:43.287084Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ca58786007c40063e8364dd7be5a851",
     "grade": false,
     "grade_id": "cell-57cbd26d204c9df4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e84bcde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T18:25:44.631182Z",
     "start_time": "2021-11-26T18:25:44.625404Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5ab2e4ebd7731a14417f6a76a8faec7",
     "grade": true,
     "grade_id": "cell-adb45e9c610a0e80",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if 'words' not in globals():\n",
    "    print(\"Use name words for a data structure for cleaned words, please.\")\n",
    "\n",
    "if len(words)>3000: print(\"You may have placed all the words in one single list, not as a list of sentences.\")\n",
    "assert(len(words)==2491), \"Check that your words is a list sentences, which are list of words\"\n",
    "\n",
    "if len(words[0])>6: print(\"Perhaps you forgot to exclude words shorter than 5 characters\") \n",
    "assert(len(words[0])==6), \"Check that each item in the list is a sigle sentence\"\n",
    "\n",
    "if words[0][0]=='Innovation': print (\"Convert to lowercase. You may use token.lower() to convert a token to lowercase\")\n",
    "assert(words[0][0]=='innovation')\n",
    "    \n",
    "if (words[8][6]=='attacks'): print(\"You probably forgot to lemmatize words\")\n",
    "assert(words[8][6]=='attack')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080be7d7",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Make an LDA model of the text data\n",
    " - Create a dictionary of words, with gensim\n",
    " - Create a bag of words (bow) from the words using the dictionary, and name it as corpus\n",
    " - Make the ldamodel. Try using 8 topics and 15 passes. Use default values for most of the fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30345c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T18:25:50.570903Z",
     "start_time": "2021-11-26T18:25:44.632197Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb93cb85420a09db9e793239796ced77",
     "grade": false,
     "grade_id": "cell-fbcbc38e4a09bb2e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25597c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T18:25:50.575645Z",
     "start_time": "2021-11-26T18:25:50.572125Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c88972018aa9e85b3b7f0e8748195986",
     "grade": true,
     "grade_id": "cell-ce13a392c5c99cf9",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if 'dictionary' not in globals():\n",
    "    print(\"Use variable dictionary for dictionary, please.\")\n",
    "\n",
    "if 'corpus' not in globals():\n",
    "    print(\"Use variable corpus for bag of words, please.\")\n",
    "\n",
    "assert(dictionary.id2token[1]=='database')\n",
    "assert(len(corpus)==2491)\n",
    "assert(len(corpus[0])==6)\n",
    "assert(len(ldamodel.show_topic(1))==10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c429e123",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T16:36:43.996227Z",
     "start_time": "2021-11-26T16:36:43.844659Z"
    }
   },
   "source": [
    "## Visualize LDA model\n",
    "\n",
    "- Visualize the lda model using pyLDAVis, store the prepared visualization as name `vis`\n",
    "- Adjust the relevance metric $\\lambda=0.2$Â from the interactive slider and try to think names for some clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc83157",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T18:26:28.727179Z",
     "start_time": "2021-11-26T18:26:28.031080Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c46b96f90c8d202363a00a91b8ff1bdc",
     "grade": false,
     "grade_id": "cell-9c21b1f39d729d72",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97d3d0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T18:27:01.223347Z",
     "start_time": "2021-11-26T18:27:01.215485Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7664295f2b7916e49f1fe29f631cf524",
     "grade": true,
     "grade_id": "cell-981444b48cd3543a",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if 'vis' not in globals():\n",
    "    print(\"Use variable vis for prepared visualization, please.\")\n",
    "\n",
    "assert(vis.topic_info.shape[1]==6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
